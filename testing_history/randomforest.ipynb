{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23c0f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./mon_standard.pkl\", 'rb') as fi: \n",
    "    mon_data = pickle.load(fi)\n",
    "\n",
    "with open('./unmon_standard10.pkl', 'rb') as f1: \n",
    "    unmon_data = pickle.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f279d089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Mon samples: 19000\n",
      "Total Unmon samples: 10000\n"
     ]
    }
   ],
   "source": [
    "USE_SUBLABEL = False\n",
    "URL_PER_SITE = 10\n",
    "TOTAL_URLS   = 950\n",
    "\n",
    "mon_X1 = [] # Array to store instances (timestamps) - 19,000 instances, e.g., [[0.0, 0.5, 3.4, ...], [0.0, 4.5, ...], [0.0, 1.5, ...], ... [... ,45.8]]\n",
    "mon_X2 = [] # Array to store instances (direction*size) - size information\n",
    "mon_y = [] # Array to store the site of each instance - 19,000 instances, e.g., [0, 0, 0, 0, 0, 0, ..., 94, 94, 94, 94, 94]\n",
    "\n",
    "\n",
    "# Differentiate instances and sites, and store them in the respective x and y arrays\n",
    "# x array (direction*timestamp), y array (site label)\n",
    "for i in range(TOTAL_URLS):\n",
    "    if USE_SUBLABEL:\n",
    "        label = i\n",
    "    else:\n",
    "        label = i // URL_PER_SITE # Calculate which site's URL the current URL being processed belongs to and set that value as the label. Thus, URLs fetched from the same site are labeled identically.\n",
    "    for sample in mon_data[i]:\n",
    "        size_seq = []\n",
    "        time_seq = []\n",
    "        for c in sample:\n",
    "            dr = 1 if c > 0 else -1\n",
    "            time_seq.append(abs(c))\n",
    "            size_seq.append(dr * 512)\n",
    "        # print(len(time_seq))\n",
    "        mon_X1.append(time_seq)\n",
    "        mon_X2.append(size_seq)\n",
    "        mon_y.append(label)\n",
    "mon_size = len(mon_y)\n",
    "\n",
    "print(f'Total Mon samples: {mon_size}') # Output: 19000\n",
    "\n",
    "\n",
    "UNMON_TOTAL_URLS = 10000\n",
    "unmon_X1 = [] # Array to store instances (timestamps) - 10,000 instances, e.g., [[0.0, 0.5, 3.4, ...], [0.0, 4.5, ...], [0.0, 1.5, ...], ... [... ,45.8]]\n",
    "unmon_X2 = [] # Array to store instances (direction*size) - size information\n",
    "\n",
    "for i in range(UNMON_TOTAL_URLS):\n",
    "    size_seq = []\n",
    "    time_seq = []\n",
    "    for c in unmon_data[i]:\n",
    "        dr = 1 if c > 0 else -1\n",
    "        time_seq.append(abs(c))\n",
    "        size_seq.append(dr * 512) # In the pickle file, there is no size information, so the conversion code is set to multiply by 512 uniformly.\n",
    "    unmon_X1.append(time_seq)\n",
    "    unmon_X2.append(size_seq)\n",
    "unmon_size = len(unmon_X1)\n",
    "unmon_y = [ 95 for sample_idx in range(unmon_size)]\n",
    "print(f'Total Unmon samples: {unmon_size}') # Output: 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a271cd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data X1 feature shape: (29000,)\n",
      "Total data X2 shape: (29000,)\n",
      "Total data y_multi shape: (29000,)\n",
      "Total data y_binary shape: (29000,)\n"
     ]
    }
   ],
   "source": [
    "X1 = mon_X1 + unmon_X1 \n",
    "X1 = np.array(X1,dtype=object)\n",
    "X2 = mon_X2 + unmon_X2\n",
    "X2 = np.array(X2,dtype=object)\n",
    "# feature기반으로 test data생성할 때 넣는 y값이 다름\n",
    "y_multi = mon_y + unmon_y\n",
    "y_binary = [1 for sample_idx in range(mon_size)] + unmon_y\n",
    "y_multi = np.array(y_multi, dtype=object)\n",
    "y_binary = np.array(y_binary, dtype=object)\n",
    "\n",
    "print(f\"Total data X1 feature shape: {X1.shape}\")\n",
    "print(f\"Total data X2 shape: {X2.shape}\")\n",
    "print(f\"Total data y_multi shape: {y_multi.shape}\")\n",
    "print(f\"Total data y_binary shape: {y_binary.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. number of incoming packets\n",
    "incoming_packets = [np.sum(np.array(sub_array) < 0) for sub_array in X2]\n",
    "incoming_packets = np.array(incoming_packets).reshape(-1, 1)\n",
    "\n",
    "# 2. the total number of incoming packets stats in first 30 packets\n",
    "incoming_packets_in_first_30_packets = [np.sum(np.array(sub_array[:30]) < 0) for sub_array in X2]\n",
    "incoming_packets_in_first_30_packets = np.array(incoming_packets_in_first_30_packets).reshape(-1, 1)\n",
    "\n",
    "# 3. the total number of outcoming packets stats in first 30 packets\n",
    "outgoing_packets_in_first_30_packets = [np.sum(np.array(sub_array[:30]) > 0) for sub_array in X2]\n",
    "outgoing_packets_in_first_30_packets = np.array(outgoing_packets_in_first_30_packets).reshape(-1, 1)\n",
    "\n",
    "# 4. number of outgoing packets as a fraction of the total number of packets\n",
    "outgoing_fraction = [np.sum(np.array(sub_array) > 0) / len(sub_array) if len(sub_array) != 0 else 0 for sub_array in X2]\n",
    "outgoing_fraction = np.array(outgoing_fraction).reshape(-1, 1)\n",
    "\n",
    "# 5. total number of packets\n",
    "total_packets_count = [len(sub_array) for sub_array in X2]\n",
    "total_packets_count = np.array(total_packets_count)\n",
    "total_packets_count_2D = total_packets_count.reshape(-1, 1)\n",
    "\n",
    "# 6. Compute fraction of incoming packets for each entry in X2\n",
    "incoming_fraction = [np.sum(np.array(sub_array) < 0) / len(sub_array) if len(sub_array) != 0 else 0 for sub_array in X2]\n",
    "incoming_fraction = np.array(incoming_fraction).reshape(-1, 1)\n",
    "\n",
    "# 7. number of outgoing packets\n",
    "outgoing_packets = [np.sum(np.array(sub_array) > 0) for sub_array in X2]\n",
    "outgoing_packets = np.array(outgoing_packets).reshape(-1, 1)\n",
    "\n",
    "# 8. standard deviation of the outgoing packet ordering list\n",
    "std_deviation_outgoing = [np.std(sub_array) for sub_array in X2]\n",
    "std_deviation_outgoing = np.array(std_deviation_outgoing).reshape(-1, 1)\n",
    "\n",
    "# 9. \n",
    "avg_outgoing_order = []\n",
    "for time_seq, size_seq in zip(X1, X2):\n",
    "    outgoing_times = [t for t, s in zip(time_seq, size_seq) if s > 0]\n",
    "    avg_outgoing_order.append(np.mean(outgoing_times) if outgoing_times else 0)\n",
    "avg_outgoing_order = np.array(avg_outgoing_order).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# 10.\n",
    "incoming_counts = []\n",
    "outgoing_counts = []\n",
    "total_counts = []\n",
    "combined_counts = []\n",
    "\n",
    "for size_seq in X2:\n",
    "    incoming_counts.append(np.sum(np.array(size_seq) < 0))\n",
    "    outgoing_counts.append(np.sum(np.array(size_seq) > 0))\n",
    "    total_counts.append(len(size_seq))\n",
    "total_counts = np.array(total_counts).reshape(-1, 1)\n",
    "\n",
    "# 11. Sum of incoming, outgoing and total number of packets\n",
    "for i in range(len(total_counts)):\n",
    "    combined_count = incoming_counts[i] + outgoing_counts[i] + total_counts[i]\n",
    "    combined_counts.append(combined_count)\n",
    "combined_counts = np.array(combined_counts).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# 12.\n",
    "packet_concentration = []\n",
    "\n",
    "for time_seq in X1:\n",
    "    # Packet Concentration: Calculate time differences between packets\n",
    "    if len(time_seq) > 1:\n",
    "        time_diffs = np.diff(time_seq)\n",
    "        concentration_feature = np.mean(time_diffs)  # 평균 시간 간격\n",
    "    else:\n",
    "        concentration_feature = 0  # 패킷이 하나 뿐인 경우\n",
    "\n",
    "    packet_concentration.append(concentration_feature)\n",
    "packet_concentration = np.array(packet_concentration).reshape(-1, 1)\n",
    "\n",
    "print(f\"1. feature shape : {incoming_packets.shape}\")\n",
    "print(f\"2. feature shape : {incoming_packets_in_first_30_packets.shape}\")\n",
    "print(f\"3. feature shape : {outgoing_packets_in_first_30_packets.shape}\")\n",
    "print(f\"4. feature shape : {outgoing_fraction.shape}\")\n",
    "print(f\"5. feature shape : {total_packets_count_2D.shape}\")\n",
    "print(f\"6. feature shape : {incoming_fraction.shape}\")\n",
    "print(f\"7. feature shape : {outgoing_packets.shape}\")\n",
    "print(f\"8. feature shape : {std_deviation_outgoing.shape}\")\n",
    "print(f\"9. feature shape : {avg_outgoing_order.shape}\")\n",
    "print(f\"10. feature shape : {total_counts.shape}\")\n",
    "print(f\"11. feature shape : {combined_counts.shape}\")\n",
    "print(f\"12. feature shape : {packet_concentration.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b810abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = np.hstack((\n",
    "    incoming_packets,\n",
    "    incoming_packets_in_first_30_packets,\n",
    "    outgoing_packets_in_first_30_packets,\n",
    "    outgoing_fraction,\n",
    "    total_packets_count_2D,\n",
    "    incoming_fraction,\n",
    "    outgoing_packets,\n",
    "    std_deviation_outgoing,\n",
    "    avg_outgoing_order,\n",
    "    total_counts,\n",
    "    combined_counts,\n",
    "    packet_concentration\n",
    ")).astype(np.float64) \n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "# for binary test and multi test\n",
    "y_binary_test = label_encoder.fit_transform(y_binary)\n",
    "y_multi_test = label_encoder.fit_transform(y_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7afa8e6",
   "metadata": {},
   "source": [
    "# Open World - binary class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72c44de",
   "metadata": {},
   "source": [
    "## Random Forest with entire features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c075710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8248275862068966\n",
      "Confusion Matrix:\n",
      "[[4345  435]\n",
      " [ 835 1635]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87      4780\n",
      "           1       0.79      0.66      0.72      2470\n",
      "\n",
      "    accuracy                           0.82      7250\n",
      "   macro avg       0.81      0.79      0.80      7250\n",
      "weighted avg       0.82      0.82      0.82      7250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_binary_test, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the RandomForest model\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528bc384",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning Random Forest with entire features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2be420cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Accuracy: 0.8308965517241379\n",
      "Confusion Matrix:\n",
      "[[4534  246]\n",
      " [ 980 1490]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      4780\n",
      "           1       0.86      0.60      0.71      2470\n",
      "\n",
      "    accuracy                           0.83      7250\n",
      "   macro avg       0.84      0.78      0.79      7250\n",
      "weighted avg       0.83      0.83      0.82      7250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search model\n",
    "grid_search.fit(X_combined, y_binary_test)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Use the best estimator for prediction\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the best parameters and evaluation metrics\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27bbe65",
   "metadata": {},
   "source": [
    "## Random Foreset with top 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fcb66f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7958620689655173\n",
      "Confusion Matrix:\n",
      "[[4240  540]\n",
      " [ 940 1530]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85      4780\n",
      "           1       0.74      0.62      0.67      2470\n",
      "\n",
      "    accuracy                           0.80      7250\n",
      "   macro avg       0.78      0.75      0.76      7250\n",
      "weighted avg       0.79      0.80      0.79      7250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_combined, y_binary_test)\n",
    "\n",
    "feature_importances = clf.feature_importances_\n",
    "top5_indices = feature_importances.argsort()[-5:][::-1]\n",
    "top5_features = X_combined[:, top5_indices]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(top5_features, y_binary_test, test_size=0.25, random_state=42)\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe275140",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning Random Forest with top 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1630b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy: 0.8293793103448276\n",
      "Confusion Matrix:\n",
      "[[4396  384]\n",
      " [ 853 1617]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88      4780\n",
      "           1       0.81      0.65      0.72      2470\n",
      "\n",
      "    accuracy                           0.83      7250\n",
      "   macro avg       0.82      0.79      0.80      7250\n",
      "weighted avg       0.83      0.83      0.82      7250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_binary_test, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Train the grid search model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Use the best estimator for prediction\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the best parameters and evaluation metrics\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0eb34d",
   "metadata": {},
   "source": [
    "# Open World - Multi class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92641706",
   "metadata": {},
   "source": [
    "## Random Forest with entire features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58745c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6685517241379311\n",
      "Confusion Matrix:\n",
      "[[  14    0    0 ...    1    1   12]\n",
      " [   0   26    0 ...    0    0   20]\n",
      " [   0    0   37 ...    0    0    7]\n",
      " ...\n",
      " [   0    0    0 ...   48    0    2]\n",
      " [   0    0    0 ...    0   20    9]\n",
      " [  10    8    5 ...    1    6 2024]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.33      0.37        42\n",
      "           1       0.70      0.51      0.59        51\n",
      "           2       0.76      0.79      0.77        47\n",
      "           3       0.61      0.49      0.54        51\n",
      "           4       0.57      0.70      0.62        43\n",
      "           5       0.68      0.68      0.68        44\n",
      "           6       0.77      0.94      0.85        53\n",
      "           7       0.68      0.69      0.68        55\n",
      "           8       0.67      0.70      0.69        47\n",
      "           9       0.58      0.47      0.52        45\n",
      "          10       0.69      0.50      0.58        44\n",
      "          11       0.71      0.49      0.58        55\n",
      "          12       0.79      0.87      0.83        52\n",
      "          13       0.56      0.40      0.47        57\n",
      "          14       0.65      0.41      0.51        58\n",
      "          15       0.65      0.72      0.68        46\n",
      "          16       0.77      0.56      0.65        59\n",
      "          17       0.56      0.45      0.50        51\n",
      "          18       0.81      0.70      0.75        50\n",
      "          19       0.66      0.78      0.71        45\n",
      "          20       0.94      0.88      0.91        52\n",
      "          21       0.86      0.12      0.22        48\n",
      "          22       0.60      0.53      0.56        47\n",
      "          23       0.82      0.67      0.74        42\n",
      "          24       0.43      0.27      0.33        48\n",
      "          25       0.66      0.61      0.63        54\n",
      "          26       0.67      0.68      0.67        47\n",
      "          27       0.57      0.40      0.47        57\n",
      "          28       0.83      0.81      0.82        48\n",
      "          29       0.50      0.59      0.54        39\n",
      "          30       0.68      0.74      0.71        43\n",
      "          31       0.67      0.63      0.65        49\n",
      "          32       0.62      0.39      0.48        54\n",
      "          33       0.67      0.57      0.62        54\n",
      "          34       0.58      0.22      0.32        49\n",
      "          35       0.58      0.55      0.56        40\n",
      "          36       0.69      0.75      0.72        44\n",
      "          37       0.60      0.30      0.40        60\n",
      "          38       0.55      0.55      0.55        55\n",
      "          39       0.55      0.57      0.56        46\n",
      "          40       0.61      0.38      0.47        58\n",
      "          41       0.85      0.79      0.82        57\n",
      "          42       0.47      0.51      0.49        47\n",
      "          43       0.79      0.78      0.78        49\n",
      "          44       0.86      0.93      0.90        46\n",
      "          45       0.42      0.33      0.37        52\n",
      "          46       0.70      0.47      0.56        45\n",
      "          47       0.57      0.48      0.52        54\n",
      "          48       0.59      0.36      0.45        47\n",
      "          49       0.75      0.75      0.75        52\n",
      "          50       0.71      0.73      0.72        49\n",
      "          51       0.47      0.28      0.35        61\n",
      "          52       0.75      0.72      0.73        53\n",
      "          53       0.52      0.62      0.57        40\n",
      "          54       0.74      0.65      0.69        57\n",
      "          55       0.48      0.30      0.37        54\n",
      "          56       0.90      0.90      0.90        49\n",
      "          57       0.52      0.56      0.54        39\n",
      "          58       0.88      0.73      0.80        52\n",
      "          59       0.86      0.82      0.84        51\n",
      "          60       0.84      0.69      0.76        54\n",
      "          61       0.58      0.54      0.56        56\n",
      "          62       0.71      0.61      0.65        61\n",
      "          63       0.63      0.49      0.55        55\n",
      "          64       0.46      0.57      0.51        42\n",
      "          65       0.61      0.46      0.52        59\n",
      "          66       0.53      0.59      0.56        41\n",
      "          67       0.76      0.66      0.70        58\n",
      "          68       0.39      0.19      0.26        47\n",
      "          69       0.61      0.56      0.58        45\n",
      "          70       0.98      0.87      0.92        47\n",
      "          71       0.60      0.73      0.66        45\n",
      "          72       0.61      0.57      0.59        58\n",
      "          73       0.83      0.83      0.83        58\n",
      "          74       0.49      0.44      0.46        66\n",
      "          75       0.85      0.91      0.88        55\n",
      "          76       0.91      0.91      0.91        44\n",
      "          77       0.54      0.36      0.43        59\n",
      "          78       0.50      0.42      0.45        53\n",
      "          79       0.60      0.47      0.53        53\n",
      "          80       0.74      0.75      0.75        53\n",
      "          81       0.63      0.60      0.61        45\n",
      "          82       0.64      0.55      0.59        55\n",
      "          83       0.66      0.76      0.70        50\n",
      "          84       0.60      0.65      0.62        48\n",
      "          85       0.75      0.87      0.80        54\n",
      "          86       0.85      0.98      0.91        51\n",
      "          87       0.74      0.49      0.59        51\n",
      "          88       0.78      0.63      0.70        49\n",
      "          89       0.36      0.36      0.36        44\n",
      "          90       0.52      0.55      0.53        44\n",
      "          91       0.58      0.57      0.58        37\n",
      "          92       0.49      0.40      0.44        52\n",
      "          93       0.76      0.83      0.79        58\n",
      "          94       0.44      0.40      0.42        50\n",
      "          95       0.68      0.82      0.74      2470\n",
      "\n",
      "    accuracy                           0.67      7250\n",
      "   macro avg       0.66      0.60      0.62      7250\n",
      "weighted avg       0.66      0.67      0.66      7250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_multi_test, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "random_forest_multi = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the RandomForestClassifier model\n",
    "random_forest_multi.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = random_forest_multi.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57890a0c",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97c1c360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hwanghyejeong/.local/share/virtualenvs/machine-learning-project-zPjYijDc/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy: 0.6702068965517242\n",
      "Confusion Matrix:\n",
      "[[  13    0    0 ...    1    1   14]\n",
      " [   0   24    0 ...    0    0   22]\n",
      " [   0    0   39 ...    0    0    5]\n",
      " ...\n",
      " [   0    0    0 ...   48    0    2]\n",
      " [   0    0    0 ...    0   20   10]\n",
      " [   9    8    5 ...    1    5 2036]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.31      0.36        42\n",
      "           1       0.67      0.47      0.55        51\n",
      "           2       0.76      0.83      0.80        47\n",
      "           3       0.61      0.49      0.54        51\n",
      "           4       0.55      0.67      0.60        43\n",
      "           5       0.66      0.66      0.66        44\n",
      "           6       0.75      0.94      0.83        53\n",
      "           7       0.68      0.73      0.70        55\n",
      "           8       0.70      0.70      0.70        47\n",
      "           9       0.53      0.40      0.46        45\n",
      "          10       0.71      0.50      0.59        44\n",
      "          11       0.70      0.47      0.57        55\n",
      "          12       0.78      0.87      0.82        52\n",
      "          13       0.57      0.40      0.47        57\n",
      "          14       0.69      0.41      0.52        58\n",
      "          15       0.64      0.70      0.67        46\n",
      "          16       0.79      0.58      0.67        59\n",
      "          17       0.55      0.45      0.49        51\n",
      "          18       0.82      0.66      0.73        50\n",
      "          19       0.69      0.80      0.74        45\n",
      "          20       0.94      0.90      0.92        52\n",
      "          21       0.78      0.15      0.25        48\n",
      "          22       0.60      0.51      0.55        47\n",
      "          23       0.78      0.69      0.73        42\n",
      "          24       0.50      0.31      0.38        48\n",
      "          25       0.70      0.65      0.67        54\n",
      "          26       0.69      0.70      0.69        47\n",
      "          27       0.59      0.40      0.48        57\n",
      "          28       0.81      0.81      0.81        48\n",
      "          29       0.51      0.62      0.56        39\n",
      "          30       0.68      0.74      0.71        43\n",
      "          31       0.65      0.61      0.63        49\n",
      "          32       0.62      0.39      0.48        54\n",
      "          33       0.65      0.56      0.60        54\n",
      "          34       0.53      0.20      0.29        49\n",
      "          35       0.59      0.55      0.57        40\n",
      "          36       0.67      0.75      0.71        44\n",
      "          37       0.59      0.27      0.37        60\n",
      "          38       0.55      0.56      0.56        55\n",
      "          39       0.56      0.50      0.53        46\n",
      "          40       0.61      0.38      0.47        58\n",
      "          41       0.85      0.79      0.82        57\n",
      "          42       0.50      0.53      0.52        47\n",
      "          43       0.83      0.78      0.80        49\n",
      "          44       0.88      0.93      0.91        46\n",
      "          45       0.43      0.35      0.38        52\n",
      "          46       0.73      0.53      0.62        45\n",
      "          47       0.58      0.46      0.52        54\n",
      "          48       0.56      0.38      0.46        47\n",
      "          49       0.78      0.75      0.76        52\n",
      "          50       0.71      0.73      0.72        49\n",
      "          51       0.51      0.31      0.39        61\n",
      "          52       0.76      0.72      0.74        53\n",
      "          53       0.53      0.62      0.57        40\n",
      "          54       0.76      0.65      0.70        57\n",
      "          55       0.45      0.26      0.33        54\n",
      "          56       0.90      0.90      0.90        49\n",
      "          57       0.54      0.56      0.55        39\n",
      "          58       0.89      0.77      0.82        52\n",
      "          59       0.85      0.80      0.83        51\n",
      "          60       0.88      0.70      0.78        54\n",
      "          61       0.55      0.52      0.53        56\n",
      "          62       0.66      0.61      0.63        61\n",
      "          63       0.58      0.47      0.52        55\n",
      "          64       0.45      0.57      0.51        42\n",
      "          65       0.60      0.46      0.52        59\n",
      "          66       0.53      0.61      0.57        41\n",
      "          67       0.80      0.67      0.73        58\n",
      "          68       0.36      0.17      0.23        47\n",
      "          69       0.62      0.58      0.60        45\n",
      "          70       0.98      0.91      0.95        47\n",
      "          71       0.59      0.76      0.66        45\n",
      "          72       0.62      0.59      0.60        58\n",
      "          73       0.81      0.83      0.82        58\n",
      "          74       0.48      0.45      0.47        66\n",
      "          75       0.85      0.91      0.88        55\n",
      "          76       0.91      0.91      0.91        44\n",
      "          77       0.43      0.27      0.33        59\n",
      "          78       0.47      0.36      0.41        53\n",
      "          79       0.68      0.47      0.56        53\n",
      "          80       0.74      0.75      0.75        53\n",
      "          81       0.65      0.62      0.64        45\n",
      "          82       0.64      0.55      0.59        55\n",
      "          83       0.68      0.76      0.72        50\n",
      "          84       0.56      0.65      0.60        48\n",
      "          85       0.77      0.85      0.81        54\n",
      "          86       0.86      0.98      0.92        51\n",
      "          87       0.81      0.51      0.63        51\n",
      "          88       0.72      0.63      0.67        49\n",
      "          89       0.36      0.36      0.36        44\n",
      "          90       0.57      0.57      0.57        44\n",
      "          91       0.60      0.57      0.58        37\n",
      "          92       0.51      0.38      0.44        52\n",
      "          93       0.77      0.83      0.80        58\n",
      "          94       0.49      0.40      0.44        50\n",
      "          95       0.68      0.82      0.74      2470\n",
      "\n",
      "    accuracy                           0.67      7250\n",
      "   macro avg       0.66      0.60      0.62      7250\n",
      "weighted avg       0.67      0.67      0.66      7250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_multi_test, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "random_forest_multi = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=random_forest_multi, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Train the grid search model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Use the best estimator for prediction\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the best parameters and evaluation metrics\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a8941",
   "metadata": {},
   "source": [
    "## Random Forest with top 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4528f9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5282758620689655\n",
      "Confusion Matrix:\n",
      "[[   3    0    0 ...    0    0   12]\n",
      " [   0   20    2 ...    0    0   23]\n",
      " [   0    3   17 ...    0    0   24]\n",
      " ...\n",
      " [   0    0    0 ...   39    0    4]\n",
      " [   2    0    0 ...    0   12    5]\n",
      " [   7   14    7 ...    0    6 1970]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.07      0.09        42\n",
      "           1       0.47      0.39      0.43        51\n",
      "           2       0.49      0.36      0.41        47\n",
      "           3       0.37      0.20      0.26        51\n",
      "           4       0.35      0.44      0.39        43\n",
      "           5       0.45      0.45      0.45        44\n",
      "           6       0.59      0.77      0.67        53\n",
      "           7       0.41      0.33      0.36        55\n",
      "           8       0.57      0.51      0.54        47\n",
      "           9       0.48      0.29      0.36        45\n",
      "          10       0.37      0.36      0.37        44\n",
      "          11       0.44      0.31      0.36        55\n",
      "          12       0.60      0.69      0.64        52\n",
      "          13       0.25      0.14      0.18        57\n",
      "          14       0.57      0.40      0.47        58\n",
      "          15       0.33      0.28      0.31        46\n",
      "          16       0.66      0.36      0.46        59\n",
      "          17       0.28      0.20      0.23        51\n",
      "          18       0.54      0.50      0.52        50\n",
      "          19       0.29      0.31      0.30        45\n",
      "          20       0.80      0.83      0.81        52\n",
      "          21       0.22      0.08      0.12        48\n",
      "          22       0.33      0.30      0.31        47\n",
      "          23       0.57      0.60      0.58        42\n",
      "          24       0.20      0.17      0.18        48\n",
      "          25       0.51      0.33      0.40        54\n",
      "          26       0.48      0.62      0.54        47\n",
      "          27       0.26      0.14      0.18        57\n",
      "          28       0.57      0.56      0.57        48\n",
      "          29       0.57      0.54      0.55        39\n",
      "          30       0.70      0.70      0.70        43\n",
      "          31       0.51      0.41      0.45        49\n",
      "          32       0.20      0.09      0.13        54\n",
      "          33       0.38      0.28      0.32        54\n",
      "          34       0.10      0.06      0.08        49\n",
      "          35       0.50      0.30      0.37        40\n",
      "          36       0.65      0.68      0.67        44\n",
      "          37       0.24      0.08      0.12        60\n",
      "          38       0.42      0.40      0.41        55\n",
      "          39       0.35      0.43      0.39        46\n",
      "          40       0.41      0.21      0.28        58\n",
      "          41       0.56      0.44      0.49        57\n",
      "          42       0.29      0.26      0.27        47\n",
      "          43       0.63      0.59      0.61        49\n",
      "          44       0.63      0.59      0.61        46\n",
      "          45       0.35      0.31      0.33        52\n",
      "          46       0.32      0.20      0.25        45\n",
      "          47       0.41      0.35      0.38        54\n",
      "          48       0.33      0.19      0.24        47\n",
      "          49       0.55      0.44      0.49        52\n",
      "          50       0.45      0.51      0.48        49\n",
      "          51       0.29      0.20      0.24        61\n",
      "          52       0.65      0.60      0.63        53\n",
      "          53       0.38      0.45      0.41        40\n",
      "          54       0.56      0.33      0.42        57\n",
      "          55       0.20      0.09      0.13        54\n",
      "          56       0.63      0.63      0.63        49\n",
      "          57       0.35      0.38      0.37        39\n",
      "          58       0.67      0.62      0.64        52\n",
      "          59       0.63      0.78      0.70        51\n",
      "          60       0.40      0.35      0.38        54\n",
      "          61       0.31      0.20      0.24        56\n",
      "          62       0.43      0.31      0.36        61\n",
      "          63       0.22      0.11      0.15        55\n",
      "          64       0.31      0.36      0.33        42\n",
      "          65       0.42      0.36      0.39        59\n",
      "          66       0.48      0.56      0.52        41\n",
      "          67       0.40      0.28      0.33        58\n",
      "          68       0.20      0.09      0.12        47\n",
      "          69       0.31      0.33      0.32        45\n",
      "          70       0.86      0.91      0.89        47\n",
      "          71       0.36      0.42      0.39        45\n",
      "          72       0.53      0.40      0.46        58\n",
      "          73       0.54      0.66      0.59        58\n",
      "          74       0.37      0.15      0.22        66\n",
      "          75       0.76      0.82      0.79        55\n",
      "          76       0.80      0.84      0.82        44\n",
      "          77       0.22      0.12      0.15        59\n",
      "          78       0.38      0.38      0.38        53\n",
      "          79       0.38      0.28      0.32        53\n",
      "          80       0.69      0.72      0.70        53\n",
      "          81       0.48      0.47      0.47        45\n",
      "          82       0.57      0.45      0.51        55\n",
      "          83       0.48      0.54      0.51        50\n",
      "          84       0.30      0.27      0.28        48\n",
      "          85       0.53      0.61      0.57        54\n",
      "          86       0.81      0.67      0.73        51\n",
      "          87       0.47      0.29      0.36        51\n",
      "          88       0.38      0.37      0.37        49\n",
      "          89       0.18      0.16      0.17        44\n",
      "          90       0.37      0.36      0.37        44\n",
      "          91       0.27      0.24      0.26        37\n",
      "          92       0.43      0.19      0.27        52\n",
      "          93       0.70      0.67      0.68        58\n",
      "          94       0.25      0.24      0.24        50\n",
      "          95       0.61      0.80      0.69      2470\n",
      "\n",
      "    accuracy                           0.53      7250\n",
      "   macro avg       0.44      0.40      0.41      7250\n",
      "weighted avg       0.50      0.53      0.50      7250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(top5_features, y_multi_test, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "random_forest_multi = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the RandomForestClassifier model\n",
    "random_forest_multi.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_multi = random_forest_multi.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_multi = accuracy_score(y_test, y_pred_multi)\n",
    "conf_matrix_multi = confusion_matrix(y_test, y_pred_multi)\n",
    "classification_rep_multi = classification_report(y_test, y_pred_multi)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy_multi}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_multi)\n",
    "print('Classification Report:')\n",
    "print(classification_rep_multi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab34ac0f",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning Random Forest with top 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "675829e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hwanghyejeong/.local/share/virtualenvs/machine-learning-project-zPjYijDc/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy: 0.5382068965517242\n",
      "Confusion Matrix:\n",
      "[[   2    0    0 ...    0    0   16]\n",
      " [   0   16    2 ...    0    0   27]\n",
      " [   0    3   11 ...    0    0   31]\n",
      " ...\n",
      " [   0    0    0 ...   47    0    4]\n",
      " [   0    0    0 ...    0   13    9]\n",
      " [   6   13    7 ...    0    3 2091]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.05      0.07        42\n",
      "           1       0.43      0.31      0.36        51\n",
      "           2       0.42      0.23      0.30        47\n",
      "           3       0.46      0.22      0.29        51\n",
      "           4       0.37      0.44      0.40        43\n",
      "           5       0.53      0.45      0.49        44\n",
      "           6       0.57      0.74      0.64        53\n",
      "           7       0.43      0.40      0.42        55\n",
      "           8       0.59      0.43      0.49        47\n",
      "           9       0.50      0.27      0.35        45\n",
      "          10       0.39      0.30      0.34        44\n",
      "          11       0.52      0.31      0.39        55\n",
      "          12       0.62      0.69      0.65        52\n",
      "          13       0.32      0.16      0.21        57\n",
      "          14       0.68      0.36      0.47        58\n",
      "          15       0.36      0.20      0.25        46\n",
      "          16       0.67      0.37      0.48        59\n",
      "          17       0.41      0.14      0.21        51\n",
      "          18       0.59      0.46      0.52        50\n",
      "          19       0.27      0.29      0.28        45\n",
      "          20       0.82      0.87      0.84        52\n",
      "          21       0.38      0.06      0.11        48\n",
      "          22       0.28      0.28      0.28        47\n",
      "          23       0.60      0.57      0.59        42\n",
      "          24       0.23      0.23      0.23        48\n",
      "          25       0.54      0.28      0.37        54\n",
      "          26       0.46      0.55      0.50        47\n",
      "          27       0.32      0.14      0.20        57\n",
      "          28       0.64      0.56      0.60        48\n",
      "          29       0.54      0.54      0.54        39\n",
      "          30       0.70      0.72      0.71        43\n",
      "          31       0.59      0.39      0.47        49\n",
      "          32       0.28      0.13      0.18        54\n",
      "          33       0.42      0.20      0.27        54\n",
      "          34       0.22      0.08      0.12        49\n",
      "          35       0.50      0.28      0.35        40\n",
      "          36       0.70      0.73      0.71        44\n",
      "          37       0.31      0.07      0.11        60\n",
      "          38       0.41      0.38      0.40        55\n",
      "          39       0.37      0.41      0.39        46\n",
      "          40       0.30      0.12      0.17        58\n",
      "          41       0.60      0.44      0.51        57\n",
      "          42       0.32      0.26      0.29        47\n",
      "          43       0.55      0.61      0.58        49\n",
      "          44       0.60      0.63      0.62        46\n",
      "          45       0.38      0.31      0.34        52\n",
      "          46       0.48      0.22      0.30        45\n",
      "          47       0.49      0.37      0.42        54\n",
      "          48       0.32      0.15      0.20        47\n",
      "          49       0.55      0.40      0.47        52\n",
      "          50       0.40      0.51      0.45        49\n",
      "          51       0.39      0.20      0.26        61\n",
      "          52       0.72      0.55      0.62        53\n",
      "          53       0.29      0.35      0.32        40\n",
      "          54       0.56      0.35      0.43        57\n",
      "          55       0.11      0.04      0.05        54\n",
      "          56       0.69      0.63      0.66        49\n",
      "          57       0.31      0.31      0.31        39\n",
      "          58       0.70      0.63      0.67        52\n",
      "          59       0.59      0.76      0.67        51\n",
      "          60       0.54      0.37      0.44        54\n",
      "          61       0.38      0.20      0.26        56\n",
      "          62       0.47      0.34      0.40        61\n",
      "          63       0.25      0.04      0.06        55\n",
      "          64       0.34      0.33      0.34        42\n",
      "          65       0.48      0.34      0.40        59\n",
      "          66       0.48      0.59      0.53        41\n",
      "          67       0.41      0.21      0.28        58\n",
      "          68       0.20      0.09      0.12        47\n",
      "          69       0.48      0.33      0.39        45\n",
      "          70       0.86      0.91      0.89        47\n",
      "          71       0.38      0.40      0.39        45\n",
      "          72       0.62      0.36      0.46        58\n",
      "          73       0.58      0.71      0.64        58\n",
      "          74       0.42      0.12      0.19        66\n",
      "          75       0.75      0.85      0.80        55\n",
      "          76       0.88      0.82      0.85        44\n",
      "          77       0.20      0.10      0.13        59\n",
      "          78       0.39      0.32      0.35        53\n",
      "          79       0.41      0.28      0.33        53\n",
      "          80       0.67      0.74      0.70        53\n",
      "          81       0.44      0.42      0.43        45\n",
      "          82       0.58      0.45      0.51        55\n",
      "          83       0.50      0.56      0.53        50\n",
      "          84       0.30      0.29      0.30        48\n",
      "          85       0.55      0.61      0.58        54\n",
      "          86       0.84      0.71      0.77        51\n",
      "          87       0.62      0.31      0.42        51\n",
      "          88       0.48      0.41      0.44        49\n",
      "          89       0.17      0.16      0.16        44\n",
      "          90       0.47      0.36      0.41        44\n",
      "          91       0.41      0.24      0.31        37\n",
      "          92       0.35      0.12      0.17        52\n",
      "          93       0.65      0.81      0.72        58\n",
      "          94       0.27      0.26      0.27        50\n",
      "          95       0.58      0.85      0.69      2470\n",
      "\n",
      "    accuracy                           0.54      7250\n",
      "   macro avg       0.47      0.39      0.41      7250\n",
      "weighted avg       0.51      0.54      0.50      7250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(top5_features, y_multi_test, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "random_forest_multi = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=random_forest_multi, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Train the grid search model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Use the best estimator for prediction\n",
    "y_pred_multi = best_estimator.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_multi = accuracy_score(y_test, y_pred_multi)\n",
    "conf_matrix_multi = confusion_matrix(y_test, y_pred_multi)\n",
    "classification_rep_multi = classification_report(y_test, y_pred_multi)\n",
    "\n",
    "# Print the best parameters and evaluation metrics\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Accuracy: {accuracy_multi}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_multi)\n",
    "print('Classification Report:')\n",
    "print(classification_rep_multi)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
